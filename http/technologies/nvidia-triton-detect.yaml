id: nvidia-triton-detect

info:
  name: Triton Inference Server - Detect
  author: mailler0xa
  severity: info
  description: |
    Detected the NVIDIA Triton Inference Server, an open-source platform for serving AI/ML models. It supported multiple frameworks and exposed HTTP/gRPC endpoints for high-performance inferencing.
  reference:
    - https://github.com/triton-inference-server/server
  metadata:
    verified: true
    max-request: 1
    vendor: nvidia
    product: triton
  tags: oss,nvidia,triton,tech

http:
  - method: GET
    path:
      - "{{BaseURL}}/v2"

    matchers-condition: and
    matchers:
      - type: word
        words:
          - "{\"name\":\"triton\","
          - "\"extensions\""
        condition: and

      - type: status
        status:
          - 200

    extractors:
      - type: json
        part: body
        json:
          - ".version"
# digest: 4a0a004730450220744aad747a607d923792f4a2acd0772c31c4f16fae2078c4bd8c897546417505022100d31d2568850ae949ecb763ef3a12cdfa162add18342fd46231464921adc960b5:922c64590222798bb761d5b6d8e72950